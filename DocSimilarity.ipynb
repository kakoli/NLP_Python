{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "python-text-mining",
      "graded_item_id": "2qbcK",
      "launcher_item_id": "pi9Sh",
      "part_id": "kQiwX"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "DocSimilarity.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxROXm_1Q4fm",
        "colab_type": "text"
      },
      "source": [
        "### Document Similarity\n",
        "Using wordnet synsets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-S2l6bOQ4fo",
        "colab_type": "code",
        "outputId": "5cfa0f10-caf6-4f5f-8113-45ad8fe51c25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import pandas as pd\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from google.colab import drive\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "!ls -al /root/nltk_data\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "dir=\"/content/gdrive/My Drive/Colab Notebooks/NLP/\"\n",
        "\n",
        "!ls\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "total 24\n",
            "drwxr-xr-x 5 root root 4096 Dec  3 03:45 .\n",
            "drwx------ 1 root root 4096 Dec  3 03:45 ..\n",
            "drwxr-xr-x 3 root root 4096 Dec  3 03:45 corpora\n",
            "drwxr-xr-x 3 root root 4096 Dec  3 03:45 taggers\n",
            "drwxr-xr-x 3 root root 4096 Dec  3 03:45 tokenizers\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "gdrive\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTgmkMbvz5F5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converts the tag given by nltk.pos_tag to a tag used by wordnet.synsets\n",
        "def convert_tag(tag):       \n",
        "    tag_dict = {'N': 'n', 'J': 'a', 'R': 'r', 'V': 'v'}\n",
        "    \n",
        "    try:\n",
        "        return tag_dict[tag[0]]\n",
        "    except KeyError:\n",
        "        return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9EIbI76TAkr",
        "colab_type": "text"
      },
      "source": [
        "#### Returns a list of synsets in document/sentence.\n",
        "\n",
        "    Example:\n",
        "        doc_to_synsets('Fish are nvqjp friends.')\n",
        "        Out: [Synset('fish.n.01'), Synset('be.v.01'), Synset('friend.n.01')]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyRJa2a9Q4fs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def doc_to_synsets(doc):    \n",
        "    token_list = nltk.word_tokenize(doc)\n",
        "    #print(token_list)\n",
        "    pos_list = nltk.pos_tag(token_list)\n",
        "    #print(pos_list)\n",
        "    \n",
        "    tag_list = [convert_tag(pos[1]) for pos in pos_list]\n",
        "    #print(tag_list)\n",
        "    \n",
        "    doc_syn_list = []\n",
        "    for token, tag in zip(token_list, tag_list):\n",
        "        syn_list = wn.synsets(token, tag)\n",
        "        if len(syn_list) > 0:\n",
        "            # Taking only the first synset. If there is no match, that token is skipped.\n",
        "            doc_syn_list.append(syn_list[0])\n",
        "    return doc_syn_list\n",
        "\n",
        "#doc_to_synsets('Fish are nvqjp friends.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-UD8RX2Tdl6",
        "colab_type": "text"
      },
      "source": [
        "#### Returns: normalized similarity score of s1 onto s2\n",
        "*Args:s1, s2: list of synsets from doc_to_synsets*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VoUoUC7MthDZ",
        "colab": {}
      },
      "source": [
        "\"\"\"For each synset in s1, finds the synset in s2 with the largest similarity value.\n",
        "    Sum of all of the largest similarity values and normalize this value by dividing it by the\n",
        "    number of largest similarity values found.\"\"\" \n",
        "\n",
        "def similarity_score(s1, s2):       \n",
        "    max_list = []\n",
        "    for syn1 in s1:\n",
        "        sim_list = []\n",
        "        for syn2 in s2:\n",
        "            word_sim = syn1.path_similarity(syn2)\n",
        "            #print(syn1, syn2, word_sim)\n",
        "            # eg - similarity(I, like) is None, discard them\n",
        "            if type(word_sim) is float:\n",
        "                sim_list.append(word_sim)\n",
        "    \n",
        "        if len(sim_list) > 0:\n",
        "            max_list.append(max(sim_list))\n",
        "            #print(syn1, sim_list, max(sim_list)) \n",
        "    #print(max_list)\n",
        "    \n",
        "    score = sum(max_list)/len(max_list)\n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odR_j4jaQ4fw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def document_path_similarity(doc1, doc2):\n",
        "    \"\"\"Finds the symmetrical similarity between doc1 and doc2\"\"\"\n",
        "    synsets1 = doc_to_synsets(doc1)\n",
        "    synsets2 = doc_to_synsets(doc2)\n",
        "\n",
        "    return (similarity_score(synsets1, synsets2) + similarity_score(synsets2, synsets1)) / 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt2OQcCsQ4fz",
        "colab_type": "code",
        "outputId": "c05f66a3-d50f-4599-a56b-521fea76f31c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# synsets1 = doc_to_synsets('I like cats')\n",
        "# synsets2 = doc_to_synsets('I like dogs')\n",
        "# similarity_score(synsets1, synsets2)\n",
        "\n",
        "print(document_path_similarity('I like cats', 'I like dogs'))\n",
        "print(document_path_similarity('I like cats', 'I do not like dogs'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7333333333333334\n",
            "0.43333333333333335\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuoZWi2PQ4f7",
        "colab_type": "text"
      },
      "source": [
        "#### Find the pair of documents in paraphrases file which has the maximum similarity score.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duLbqyiuQ4f8",
        "colab_type": "code",
        "outputId": "e60d9563-a59e-48cd-c6c4-ff80092f23e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "# `Quality` indicates if the two documents `D1` and `D2` are paraphrases of one another (1 for paraphrase, 0 for not).\n",
        "paraphrases = pd.read_csv(dir + 'paraphrases.csv')\n",
        "print(paraphrases.shape)\n",
        "paraphrases.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Quality</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Ms Stewart, the chief executive, was not expec...</td>\n",
              "      <td>Ms Stewart, 61, its chief executive officer an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>After more than two years' detention under the...</td>\n",
              "      <td>After more than two years in detention by the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>\"It still remains to be seen whether the reven...</td>\n",
              "      <td>\"It remains to be seen whether the revenue rec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>And it's going to be a wild ride,\" said Allan ...</td>\n",
              "      <td>Now the rest is just mechanical,\" said Allan H...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>The cards are issued by Mexico's consulates to...</td>\n",
              "      <td>The card is issued by Mexico's consulates to i...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Quality  ...                                                 D2\n",
              "0        1  ...  Ms Stewart, 61, its chief executive officer an...\n",
              "1        1  ...  After more than two years in detention by the ...\n",
              "2        1  ...  \"It remains to be seen whether the revenue rec...\n",
              "3        0  ...  Now the rest is just mechanical,\" said Allan H...\n",
              "4        1  ...  The card is issued by Mexico's consulates to i...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngFNrvvbQ4f_",
        "colab_type": "code",
        "outputId": "917f462c-c5e7-4fb3-a95c-037f82374b97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "def most_similar_columns():\n",
        "    score_list = []\n",
        "    \n",
        "    for index, row in paraphrases.iterrows():\n",
        "        score = document_path_similarity(row[\"D1\"], row[\"D2\"])\n",
        "        score_list.append(score)\n",
        "        \n",
        "    paraphrases[\"score\"] = score_list\n",
        "    #print(paraphrases[\"score\"])\n",
        "    \n",
        "    max_score_index = paraphrases[\"score\"].idxmax()\n",
        "    col1 = paraphrases.loc[max_score_index].D1\n",
        "    col2 = paraphrases.loc[max_score_index].D2\n",
        "    max_score = paraphrases.loc[max_score_index].score\n",
        "    \n",
        "    max_similar =  (col1, col2, max_score)\n",
        "    return max_similar\n",
        "\n",
        "most_similar_columns()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('\"Indeed, Iran should be put on notice that efforts to try to remake Iraq in their image will be aggressively put down,\" he said.',\n",
              " '\"Iran should be on notice that attempts to remake Iraq in Iran\\'s image will be aggressively put down,\" he said.\\n',\n",
              " 0.9753086419753086)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-_OnfgCQ4gB",
        "colab_type": "text"
      },
      "source": [
        "#### Get label_accuracy\n",
        "\n",
        "Compute labels for the twenty pairs of columns by computing the similarity for each pair. If the score is greater than 0.75, actual label is (1), else (0). Report accuracy of the classifier using scikit-learn's accuracy_score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQAXznDmQ4gC",
        "colab_type": "code",
        "outputId": "ec838c7c-99ef-4233-ddc4-89efe64d4179",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def label_accuracy():\n",
        "    paraphrases[\"label\"] = np.where(paraphrases[\"score\"] > 0.75, 1, 0)\n",
        "    #print(paraphrases.head())\n",
        "    return accuracy_score(paraphrases[\"Quality\"], paraphrases[\"label\"])\n",
        "\n",
        "label_accuracy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    }
  ]
}